# Fluxo Completo de Atualiza√ß√£o: ETL ‚Üí Analytics

**Data de Cria√ß√£o**: 19 de Janeiro de 2026  
**Vers√£o**: 1.0  
**Status**: ‚úÖ Operacional

---

## üìä Vis√£o Geral do Pipeline

O sistema utiliza uma arquitetura ETL h√≠brida que extrai dados de um SQL Server remoto, processa localmente em PostgreSQL, e publica JSONs est√°ticos no Supabase Storage para consumo pelos 22 dashboards React.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         PIPELINE COMPLETO                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

   [SQL SERVER]          [NODE.JS ETL]         [POSTGRESQL]       [SUPABASE]         [REACT]
   blufleet-dw     ‚Üí    run-sync-v2.js    ‚Üí   BluConecta_Dw  ‚Üí   Storage      ‚Üí    Dashboards
       ‚îÇ                      ‚îÇ                     ‚îÇ               ‚îÇ                   ‚îÇ
  (Origem DW)         (Extra√ß√£o +             (Backup +        (JSON          (useBIData Hook)
  200+ tabelas        Transforma√ß√£o)           Cache)          Est√°ticos)      21 p√°ginas
       ‚îÇ                      ‚îÇ                     ‚îÇ               ‚îÇ                   ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                   25-48 minutos total
```

---

## üîÑ Etapas Detalhadas

### **Etapa 1: Extra√ß√£o (SQL Server ‚Üí Node.js)**

**Script**: [scripts/local-etl/run-sync-v2.js](../scripts/local-etl/run-sync-v2.js)  
**Dura√ß√£o**: 15-25 minutos  
**Tecnologia**: `mssql` (Node.js driver)

#### Processo:
1. **Conex√£o ao SQL Server**
   - Host: `200.219.192.34:3494`
   - Database: `blufleet-dw`
   - Autentica√ß√£o: SQL Server Authentication
   - Timeout: 300 segundos

2. **Execu√ß√£o de Queries**
   - 128 queries SQL parametrizadas
   - Uso de `WITH (NOLOCK)` para evitar bloqueios
   - Uso de `OPTION (MAXDOP 2)` para limitar paralelismo
   - JOINs complexos para relacionar dimens√µes

3. **Estrutura de Queries**
   ```sql
   -- Exemplo: fat_sinistros
   SELECT 
     os.IdOcorrenciaSinistro,
     os.DataOcorrencia,
     os.ValorSinistro,
     cli.IdCliente,
     cli.Cliente AS NomeCliente,
     v.IdVeiculo,
     v.Placa
   FROM OcorrenciasSinistro os WITH (NOLOCK)
   LEFT JOIN ContratosLocacao cl ON os.IdContrato = cl.IdContrato
   LEFT JOIN ContratosComerciais cc ON cl.IdContratoComercial = cc.IdContratoComercial
   LEFT JOIN Clientes cli ON cc.IdCliente = cli.IdCliente
   LEFT JOIN Veiculos v ON os.IdVeiculo = v.IdVeiculo
   WHERE os.DataOcorrencia >= '2022-01-01'
   OPTION (MAXDOP 2)
   ```

#### Dados Extra√≠dos:
| Tipo | Quantidade | Registros Totais |
|------|-----------|------------------|
| Dimens√µes | 8 tabelas | 188.159 |
| Fatos Anuais | 25 tabelas (5 anos) | 579.535 |
| Financeiro Universal | 60 meses | 414.658 |
| Consolidados | 10 tabelas | 759.052 |
| **TOTAL** | **103 arquivos** | **1.941.404 registros** |

---

### **Etapa 2: Transforma√ß√£o (Node.js)**

**Dura√ß√£o**: Inline (durante extra√ß√£o)  
**Tecnologia**: JavaScript

#### Processos:
1. **Normaliza√ß√£o de Tipos**
   ```javascript
   // Convers√£o de decimals SQL Server ‚Üí Number
   valor_km_adicional: parseFloat(row.ValorKmAdicional) || 0
   
   // Convers√£o de datas
   data_ocorrencia: row.DataOcorrencia ? 
     new Date(row.DataOcorrencia).toISOString() : null
   
   // Snake_case para campos
   id_veiculo: row.IdVeiculo
   ```

2. **Agrega√ß√µes e C√°lculos**
   - TCO (Total Cost of Ownership)
   - Margens de rentabilidade
   - KPIs consolidados (churn rate, utiliza√ß√£o de frota)

3. **Chunking Autom√°tico**
   ```javascript
   // Divis√£o de arquivos grandes (>10.000 rows)
   if (data.length > 10000) {
     const chunkSize = 10000;
     const chunks = Math.ceil(data.length / chunkSize);
     
     for (let i = 0; i < chunks; i++) {
       const chunk = data.slice(i * chunkSize, (i + 1) * chunkSize);
       await uploadChunk(fileName, i + 1, chunk, chunks);
     }
     
     // Gera manifest.json para o frontend
     await generateManifest(fileName, chunks);
   }
   ```

4. **Metadados Enriquecidos**
   ```json
   {
     "generated_at": "2026-01-19T14:30:00.000Z",
     "dw_last_update": "2026-01-19T12:00:00.000Z",
     "source": "external_sync",
     "table": "dim_frota",
     "record_count": 5780,
     "etl_version": "2.0",
     "execution_time_ms": 45234,
     "data": [...]
   }
   ```

---

### **Etapa 3: Grava√ß√£o no PostgreSQL (Opcional)**

**Dura√ß√£o**: 5-10 minutos  
**Tecnologia**: `pg` (Node.js driver)  
**Status**: ‚ö†Ô∏è Opcional (pode ser desabilitado com flag `--json-only`)

#### Processo:
1. **Truncate + Insert**
   ```sql
   -- Limpa tabela existente
   TRUNCATE TABLE bluconecta_dw.public.dim_frota CASCADE;
   
   -- Insere novos dados
   INSERT INTO bluconecta_dw.public.dim_frota 
   (id_veiculo, placa, modelo, ano, valor_fipe, ...)
   VALUES ($1, $2, $3, $4, $5, ...);
   ```

2. **Finalidade**
   - Backup local dos dados
   - Queries ad-hoc via pgAdmin
   - Suporte a foreign data wrappers (FDW)
   - N√£o √© usado diretamente pelos dashboards

#### Configura√ß√£o:
```env
PG_HOST=localhost
PG_PORT=5432
PG_USER=Quality_etl_user
PG_PASSWORD=F4tu5xy3
PG_DATABASE=BluConecta_Dw
```

---

### **Etapa 4: Upload para Supabase Storage**

**Dura√ß√£o**: 10-15 minutos  
**Tecnologia**: Supabase Edge Function  
**Endpoint**: `/functions/v1/sync-dw-to-storage`

#### Processo:
1. **Requisi√ß√£o POST**
   ```javascript
   const response = await fetch(
     'https://apqrjkobktjcyrxhqwtm.supabase.co/functions/v1/sync-dw-to-storage',
     {
       method: 'POST',
       headers: {
         'Content-Type': 'application/json',
         'Authorization': `Bearer ${SUPABASE_SERVICE_ROLE_KEY}`
       },
       body: JSON.stringify({
         fileName: 'dim_frota.json',
         data: { generated_at, record_count, data: [...] },
         metadata: { contentType: 'application/json' }
       })
     }
   );
   ```

2. **Edge Function** ([supabase/functions/sync-dw-to-storage/index.ts](../supabase/functions/sync-dw-to-storage/index.ts))
   ```typescript
   // Recebe JSON via POST
   const { fileName, data, metadata } = await req.json();
   
   // Salva no bucket bi-reports
   const { error } = await supabase.storage
     .from('bi-reports')
     .upload(fileName, JSON.stringify(data), {
       contentType: 'application/json',
       upsert: true,
       metadata
     });
   ```

3. **Estrutura do Bucket**
   ```
   bi-reports/
   ‚îú‚îÄ‚îÄ dim_clientes.json
   ‚îú‚îÄ‚îÄ dim_frota.json
   ‚îú‚îÄ‚îÄ fat_faturamentos_2022.json
   ‚îú‚îÄ‚îÄ fat_faturamentos_2023.json
   ‚îú‚îÄ‚îÄ fat_faturamentos_2024.json
   ‚îú‚îÄ‚îÄ fat_faturamentos_2025.json
   ‚îú‚îÄ‚îÄ fat_faturamentos_2026.json
   ‚îú‚îÄ‚îÄ fat_sinistros_2022.json
   ‚îú‚îÄ‚îÄ fat_sinistros_2023.json
   ‚îú‚îÄ‚îÄ fat_multas_2022.json
   ‚îú‚îÄ‚îÄ fat_multas_2023.json
   ‚îú‚îÄ‚îÄ fat_financeiro_universal_2022_01.json
   ‚îú‚îÄ‚îÄ fat_financeiro_universal_2022_02.json
   ‚îú‚îÄ‚îÄ ...
   ‚îú‚îÄ‚îÄ fat_manutencao_unificado_part_1.json
   ‚îú‚îÄ‚îÄ fat_manutencao_unificado_part_2.json
   ‚îú‚îÄ‚îÄ ...
   ‚îú‚îÄ‚îÄ fat_manutencao_unificado_manifest.json
   ‚îî‚îÄ‚îÄ (128 arquivos totais)
   ```

4. **Permiss√µes**
   - Bucket: `bi-reports` (p√∫blico para leitura)
   - RLS: Desabilitado para leitura an√¥nima
   - CORS: Habilitado para dom√≠nio Vercel

---

### **Etapa 5: Consumo pelos Dashboards**

**Hook Principal**: [src/hooks/useBIData.ts](../src/hooks/useBIData.ts)  
**Tecnologia**: React + SWR (stale-while-revalidate)  
**Cache**: 5 minutos

#### Processo:

1. **Requisi√ß√£o do Dashboard**
   ```typescript
   // Em FleetDashboard.tsx
   const { data: frota, isLoading, error } = useBIData<DimFrota[]>('dim_frota.json');
   const { data: faturamentos } = useBIData('fat_faturamentos_*.json'); // Sharding
   ```

2. **L√≥gica do Hook**
   ```typescript
   export function useBIData<T>(fileName: string) {
     const fetcher = async (url: string) => {
       // 1. Verifica cache em mem√≥ria (5 min)
       const cached = memoryCache.get(url);
       if (cached && Date.now() - cached.timestamp < 300000) {
         return cached.data;
       }
       
       // 2. Detecta sharding (* ou *_*)
       if (fileName.includes('*')) {
         return await fetchShardedFile(fileName);
       }
       
       // 3. Detecta chunking (manifest.json)
       const manifestUrl = url.replace('.json', '_manifest.json');
       const manifestRes = await fetch(manifestUrl);
       
       if (manifestRes.ok) {
         const manifest = await manifestRes.json();
         return await fetchChunkedFile(fileName, manifest);
       }
       
       // 4. Fetch simples
       const response = await fetch(url);
       if (!response.ok) throw new Error(`HTTP ${response.status}`);
       
       const json = await response.json();
       memoryCache.set(url, { data: json.data, timestamp: Date.now() });
       
       return json.data;
     };
     
     return useSWR<T>(
       `${SUPABASE_URL}/storage/v1/object/public/bi-reports/${fileName}`,
       fetcher,
       { revalidateOnFocus: false, dedupingInterval: 300000 }
     );
   }
   ```

3. **Sharding Autom√°tico**
   ```typescript
   // fat_faturamentos_*.json ‚Üí busca 2022, 2023, 2024, 2025, 2026
   async function fetchShardedFile(pattern: string) {
     const years = [2022, 2023, 2024, 2025, 2026];
     const files = years.map(year => pattern.replace('*', year.toString()));
     
     const responses = await Promise.all(
       files.map(file => fetch(`${baseUrl}/${file}`))
     );
     
     const allData = [];
     for (const res of responses) {
       if (res.ok) {
         const json = await res.json();
         allData.push(...json.data);
       }
     }
     
     return allData;
   }
   ```

4. **Chunking Autom√°tico**
   ```typescript
   // fat_manutencao_unificado.json ‚Üí l√™ manifest e combina 11 partes
   async function fetchChunkedFile(fileName: string, manifest: Manifest) {
     const { totalChunks } = manifest;
     const baseName = fileName.replace('.json', '');
     
     const chunks = await Promise.all(
       Array.from({ length: totalChunks }, (_, i) =>
         fetch(`${baseUrl}/${baseName}_part_${i + 1}.json`)
           .then(res => res.json())
           .then(json => json.data)
       )
     );
     
     return chunks.flat();
   }
   ```

#### Exemplo de Uso no Dashboard:
```typescript
// FleetDashboard.tsx
import { useBIData } from '@/hooks/useBIData';

export default function FleetDashboard() {
  const { data: frota, isLoading } = useBIData<DimFrota[]>('dim_frota.json');
  const { data: sinistros } = useBIData<FatSinistros[]>('fat_sinistros_*.json');
  const { data: multas } = useBIData<FatMultas[]>('fat_multas_*.json');
  
  if (isLoading) return <Skeleton />;
  
  const veiculosAtivos = frota?.filter(v => v.situacao === 'Ativo').length;
  const custoSinistros = sinistros?.reduce((sum, s) => sum + s.valor_sinistro, 0);
  
  return (
    <div>
      <KPICard title="Ve√≠culos Ativos" value={veiculosAtivos} />
      <KPICard title="Custo Sinistros" value={formatCurrency(custoSinistros)} />
      <BarChart data={frota} />
    </div>
  );
}
```

---

## ‚è±Ô∏è Frequ√™ncia de Atualiza√ß√£o

### **M√©todo 1: GitHub Actions (Atual)** ‚ö†Ô∏è

**Arquivo**: [.github/workflows/sync-data.yml](../.github/workflows/sync-data.yml)  
**Status**: Parcialmente ativo (modo `--json-only`)  
**Frequ√™ncia**: 3x por dia

```yaml
on:
  schedule:
    - cron: '30 13 * * *'  # 13:30 UTC = 10:30 BRT
    - cron: '30 18 * * *'  # 18:30 UTC = 15:30 BRT
    - cron: '30 3 * * *'   # 03:30 UTC = 00:30 BRT
  workflow_dispatch:       # Manual via GitHub UI
```

**Limita√ß√£o**: GitHub runner n√£o consegue conectar ao SQL Server local (200.219.192.34). S√≥ faz upload de JSONs j√° gerados, n√£o executa ETL completo.

---

### **M√©todo 2: Execu√ß√£o Local Manual (Recomendado)** ‚úÖ

**Comando**:
```bash
cd scripts/local-etl
node run-sync-v2.js
```

**Vantagens**:
- ‚úÖ Execu√ß√£o completa (SQL Server + PostgreSQL + Supabase)
- ‚úÖ Acesso direto ao SQL Server
- ‚úÖ Logs detalhados
- ‚úÖ Controle total sobre o processo

**Desvantagens**:
- ‚ö†Ô∏è Requer interven√ß√£o manual
- ‚ö†Ô∏è Dependente de m√°quina local estar ligada
- ‚ö†Ô∏è Sem alertas autom√°ticos de falha

---

### **M√©todo 3: Windows Task Scheduler (Planejado)** üöß

**PowerShell Script**:
```powershell
# Criar tarefa agendada para rodar diariamente √†s 02:00
$action = New-ScheduledTaskAction `
  -Execute 'node' `
  -Argument 'C:\Users\frant\Documents\qualia-task-flow\scripts\local-etl\run-sync-v2.js' `
  -WorkingDirectory 'C:\Users\frant\Documents\qualia-task-flow\scripts\local-etl'

$trigger = New-ScheduledTaskTrigger -Daily -At 2am

$settings = New-ScheduledTaskSettingsSet `
  -StartWhenAvailable `
  -RunOnlyIfNetworkAvailable `
  -ExecutionTimeLimit (New-TimeSpan -Hours 2)

Register-ScheduledTask `
  -TaskName "ETL BluConecta DW" `
  -Action $action `
  -Trigger $trigger `
  -Settings $settings `
  -User "SYSTEM" `
  -Description "Sincroniza√ß√£o di√°ria de dados DW ‚Üí Supabase"
```

**Vantagens**:
- ‚úÖ Autom√°tico
- ‚úÖ N√£o requer interven√ß√£o
- ‚úÖ Logs nativos do Windows

**Desvantagens**:
- ‚ö†Ô∏è Requer m√°quina sempre ligada
- ‚ö†Ô∏è Sem redund√¢ncia (se m√°quina falhar, ETL n√£o roda)

---

### **M√©todo 4: Cron Job (Linux/Docker)** üöß

```bash
# Adicionar ao crontab
0 2 * * * cd /app/scripts/local-etl && /usr/bin/node run-sync-v2.js >> /var/log/etl.log 2>&1
```

**Vantagens**:
- ‚úÖ Robusto
- ‚úÖ Integra√ß√£o com Docker
- ‚úÖ Redund√¢ncia (pode rodar em servidor dedicado)

**Status**: Planejado para fase 2 (migra√ß√£o para servidor dedicado)

---

## üìã Checklist de Execu√ß√£o Manual

### **Pr√©-requisitos**
- [ ] SQL Server acess√≠vel (`200.219.192.34:3494`)
- [ ] PostgreSQL rodando (`localhost:5432`)
- [ ] Vari√°veis de ambiente configuradas (`.env`)
- [ ] Node.js instalado (`v18+`)
- [ ] Depend√™ncias instaladas (`npm install`)

### **Verifica√ß√£o Antes de Executar**
```bash
# 1. Validar configura√ß√£o
node verify-config.js

# Sa√≠da esperada:
# ‚úÖ SQL Server: Conectado
# ‚úÖ PostgreSQL: Conectado
# ‚úÖ Supabase: Conectado
# ‚úÖ Vari√°veis de ambiente: OK
```

### **Execu√ß√£o**
```bash
# 2. Executar ETL completo
node run-sync-v2.js

# Sa√≠da esperada (simplified):
# [11:45:33] Iniciando sincroniza√ß√£o...
# [11:45:35] ‚úÖ dim_clientes (1.577 registros)
# [11:45:37] ‚úÖ dim_frota (5.780 registros)
# ...
# [11:47:08] ‚úÖ fat_manutencao_unificado_part_11.json
# [11:47:10] üéâ Conclu√≠do: 103/103 tabelas (100%)
```

### **Verifica√ß√£o P√≥s-Execu√ß√£o**
```bash
# 3. Verificar arquivos no Supabase Storage
# Acessar: https://apqrjkobktjcyrxhqwtm.supabase.co/storage/v1/object/public/bi-reports/

# 4. Testar dashboard
# Acessar: http://localhost:5173/analytics/fleet
# Verificar se dados carregam sem erro
```

---

## üö® Monitoramento e Alertas

### **Status Atual** ‚ö†Ô∏è
- ‚ùå Sem sistema de alertas autom√°tico
- ‚ùå Sem dashboard de monitoramento do ETL
- ‚ùå Sem m√©tricas de SLA (tempo de execu√ß√£o, taxa de sucesso)
- ‚úÖ Logs manuais via console

### **Plano de Melhoria** üöß

#### **Fase 1: Logging Estruturado**
```javascript
// Adicionar ao run-sync-v2.js
const winston = require('winston');

const logger = winston.createLogger({
  transports: [
    new winston.transports.File({ filename: 'etl-error.log', level: 'error' }),
    new winston.transports.File({ filename: 'etl-combined.log' })
  ]
});

logger.info('ETL iniciado', { timestamp: new Date(), tablesCount: 103 });
logger.error('Falha em fat_sinistros', { error: err.message, stack: err.stack });
```

#### **Fase 2: Webhooks de Notifica√ß√£o**
```javascript
// Notificar via Slack/Discord/Email ao final
async function notifyCompletion(stats) {
  await fetch(SLACK_WEBHOOK_URL, {
    method: 'POST',
    body: JSON.stringify({
      text: `ETL Conclu√≠do: ${stats.success}/${stats.total} tabelas em ${stats.duration}`,
      attachments: [
        {
          color: stats.success === stats.total ? 'good' : 'warning',
          fields: [
            { title: 'Registros Processados', value: stats.recordCount, short: true },
            { title: 'Tempo de Execu√ß√£o', value: `${stats.duration}min`, short: true }
          ]
        }
      ]
    })
  });
}
```

#### **Fase 3: Dashboard de Sa√∫de**
- Criar p√°gina `/analytics/etl-health`
- Exibir:
  - √öltima execu√ß√£o (timestamp)
  - Status de cada tabela (‚úÖ/‚ö†Ô∏è/‚ùå)
  - Hist√≥rico de execu√ß√µes (√∫ltimos 30 dias)
  - Tempo m√©dio de processamento por tabela
  - Alertas de anomalias (ex: queda >50% no record_count)

---

## üîß Troubleshooting

### **Problema 1: SQL Server Connection Timeout**
```
Error: Connection timeout
```

**Solu√ß√£o**:
```javascript
// Aumentar timeout em run-sync-v2.js
const config = {
  server: process.env.SQL_SERVER,
  user: process.env.SQL_USER,
  password: process.env.SQL_PASSWORD,
  database: process.env.SQL_DATABASE,
  options: {
    encrypt: false,
    trustServerCertificate: true,
    connectTimeout: 60000,  // Aumentar de 30s para 60s
    requestTimeout: 300000  // 5 minutos
  }
};
```

---

### **Problema 2: Supabase Upload Failed (413 Payload Too Large)**
```
Error: Request entity too large
```

**Solu√ß√£o**: Chunking j√° implementado automaticamente para arquivos >10K rows. Verificar se manifest est√° sendo gerado corretamente.

---

### **Problema 3: Frontend Showing Stale Data**
```
Dashboard mostra dados antigos mesmo ap√≥s ETL
```

**Solu√ß√£o**:
```typescript
// Limpar cache do useBIData manualmente
import { mutate } from 'swr';

// No componente:
const refreshData = () => {
  mutate(key => typeof key === 'string' && key.includes('bi-reports'), undefined, { revalidate: true });
};
```

---

## üìä M√©tricas de Performance

### **√öltima Execu√ß√£o (05/01/2026)**
| Etapa | Dura√ß√£o | Observa√ß√µes |
|-------|---------|-------------|
| Extra√ß√£o (SQL Server) | 15min 23s | 103 queries, 1.9M registros |
| Transforma√ß√£o | Inline | 0s adicional (processamento durante extra√ß√£o) |
| Grava√ß√£o PostgreSQL | 8min 12s | TRUNCATE + INSERT de 103 tabelas |
| Upload Supabase | 12min 35s | 128 arquivos (incluindo chunks) |
| **TOTAL** | **36min 10s** | ‚úÖ Dentro do esperado (25-48min) |

### **Tamanho dos Dados**
| Categoria | Arquivos | Tamanho Total | Maior Arquivo |
|-----------|----------|---------------|---------------|
| Dimens√µes | 8 | 42 MB | dim_veiculos_acessorios (15 MB) |
| Fatos Anuais | 25 | 128 MB | fat_detalhe_itens_os (52 MB) |
| Financeiro | 60 | 186 MB | fat_financeiro_universal_2024_12 (8 MB) |
| Consolidados | 10 | 234 MB | fat_manutencao_unificado (98 MB) |
| **TOTAL** | **103** | **590 MB** | fat_manutencao_unificado_part_1 (12 MB) |

---

## üéØ Roadmap de Melhorias

### **Q1 2026** (Curto Prazo)
- [ ] Implementar Windows Task Scheduler
- [ ] Adicionar webhooks de notifica√ß√£o (Slack)
- [ ] Criar dashboard de monitoramento ETL
- [ ] Documentar estrutura esperada de cada JSON

### **Q2 2026** (M√©dio Prazo)
- [ ] Migrar para servidor dedicado (Linux)
- [ ] Implementar retry autom√°tico em caso de falha
- [ ] Adicionar valida√ß√£o de anomalias p√≥s-ETL
- [ ] Criar testes automatizados de integridade

### **Q3 2026** (Longo Prazo)
- [ ] Avaliar migra√ß√£o de JSONs para queries diretas no Supabase Database
- [ ] Implementar incremental ETL (delta sync)
- [ ] Adicionar compress√£o gzip nos uploads
- [ ] Criar pipeline de CI/CD para deploy autom√°tico

---

## üìö Refer√™ncias

- [GUIA_RAPIDO_MIGRACAO.md](./GUIA_RAPIDO_MIGRACAO.md) - Guia de in√≠cio r√°pido
- [ETL_EXECUTION_REPORT_2026-01-05.md](./ETL_EXECUTION_REPORT_2026-01-05.md) - Relat√≥rio de execu√ß√£o detalhado
- [MAPEAMENTO_DASHBOARDS_ETL.md](./MAPEAMENTO_DASHBOARDS_ETL.md) - Mapeamento tabelas ‚Üí dashboards
- [scripts/local-etl/README.md](../scripts/local-etl/README.md) - Documenta√ß√£o t√©cnica do ETL
- [ANALYTICS_ARCHITECTURE.md](./ANALYTICS_ARCHITECTURE.md) - Arquitetura geral do m√≥dulo Analytics

---

**√öltima Atualiza√ß√£o**: 19 de Janeiro de 2026  
**Respons√°vel**: Equipe BluConecta DW  
**Status**: ‚úÖ Documenta√ß√£o Completa
